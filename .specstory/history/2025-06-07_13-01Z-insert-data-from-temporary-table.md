<!-- Generated by SpecStory -->

# Insert data from temporary table (2025-06-07 13:01Z)

_**User**_

@Codebase select ZEN_B2B_JSON_TMP 若資料筆數>0，則把所有資料insert into ZEN_B2B_JSON_SO。若select ZEN_B2B_JSON_TMP 若資料筆數=0，則跳出程式不再繼續

---

_**Assistant**_

<think><details><summary>Thought Process</summary>**Analysing the Requirement**

我正在解析使用者的要求。看起來他們想要修改 `GenericExtractService.java` 來處理資料庫的 `ZEN_B2B_JSON_TMP` 表格。重點是要根據資料筆數條件插入資料。


**Refining the Logic**

我正在深入研究使用者的要求。看起來我需要添加一個步驟來檢查 `ZEN_B2B_JSON_TMP` 表格中的資料筆數。如果資料筆數大於零，就將資料插入到 `ZEN_B2B_JSON_SO` 表格中。如果筆數為零，則直接跳出程序。我需要修改 `extract()` 方法，在執行完現有的 SQL 腳本之後新增這個檢查邏輯。目前正在思考如何有效率地實現這個邏輯，並確保程式的穩定性。


**Evaluating the Approach**

我正在評估修改 `GenericExtractService.java` 的方法。我的初步想法是在執行完現有的 SQL 腳本之後，加入一個步驟來檢查 `ZEN_B2B_JSON_TMP` 表格中的資料筆數。如果資料筆數大於零，則將資料插入到 `ZEN_B2B_JSON_SO` 表格中。如果筆數為零，就直接返回並記錄日誌。我需要確認這個做法是否符合使用者需求，以及如何確保這個流程的效率和穩定性。


**Formulating the Implementation**

我正在進一步規劃修改 `GenericExtractService.java` 的步驟。我決定在現有的 SQL 腳本執行完成後，增加一個檢查 `ZEN_B2B_JSON_TMP` 表格資料筆數的步驟。如果筆數為零，我會記錄日誌並返回 0。如果筆數大於零，則執行插入資料到 `ZEN_B2B_JSON_SO` 表格的 SQL 語句。我需要考慮如何優化這部分程式碼的執行效率，避免影響整體效能。


**Developing the Solution**

我正在著手設計具體的解決方案。我需要在 `extract()` 方法中，在現有的 SQL 腳本執行完畢之後，加入邏輯來檢查 `ZEN_B2B_JSON_TMP` 表格的資料筆數。如果資料筆數為零，我就記錄日誌並返回 0。如果筆數大於零，則執行 `INSERT INTO ZEN_B2B_JSON_SO` 的 SQL 語句。我需要考慮如何優化這部分程式碼的效能，並確保程式碼的穩定性。


**Developing the Implementation**

我正在著手設計具體的解決方案。我需要在 `extract()` 方法中，在現有的 SQL 腳本執行完畢之後，新增邏輯來檢查 `ZEN_B2B_JSON_TMP` 表格的資料筆數。如果筆數為零，我就記錄日誌並返回 0。如果筆數大於零，則執行 `INSERT INTO ZEN_B2B_JSON_SO SELECT * FROM ZEN_B2B_JSON_TMP` 的 SQL 語句。我需要考慮如何優化這部分程式碼的效能，並確保程式碼的穩定性。


**Integrating the Logic**

我正在將新的邏輯整合到 `extract()` 方法中。 在獲得 `ZEN_B2B_JSON_TMP` 表格的資料筆數後，我會檢查筆數是否為零。 如果為零，我會記錄日誌並返回。 如果筆數大於零，則執行插入 `ZEN_B2B_JSON_SO` 表格的 SQL 語句。我正在測試以確保這部分程式碼的正確性。


**Finalizing the Implementation**

我已經準備好實作 `GenericExtractService.java` 的修改了。在取得 `ZEN_B2B_JSON_TMP` 表格的資料筆數後，我將檢查筆數是否為零。 如果是零，我會記錄日誌並返回0。 否則，我會使用從 `mi_extract.sql` 獲得的欄位來執行 `INSERT INTO ZEN_B2B_JSON_SO SELECT * FROM ZEN_B2B_JSON_TMP` 語句。我會確保這部分程式碼的效率和穩定性。


**Enhancing the Procedure**

我進一步完善了程式碼。 我會在取得 `ZEN_B2B_JSON_TMP` 的資料筆數後，進行檢查。如果筆數為零，我會記錄訊息並返回。 否則，我將使用 `INSERT INTO ZEN_B2B_JSON_SO SELECT * FROM ZEN_B2B_JSON_TMP` 的語句，並確保此操作在交易中執行，以保持資料庫的一致性。 為了確保程式碼的效率和穩定性，我將對此過程進行進一步的測試。

**Refining the Solution**

我現在正著手加入檢查資料筆數的邏輯。如果資料筆數為零，我會記錄日誌並返回。如果筆數大於零，則會執行 `INSERT INTO ZEN_B2B_JSON_SO SELECT * FROM ZEN_B2B_JSON_TMP` 的 SQL 語句。我將確保在事務中執行此操作，以維持資料庫的一致性。


**Enhancing the Procedure**

我進一步完善了程式碼。 我會在取得 `ZEN_B2B_JSON_TMP` 的資料筆數後，進行檢查。如果筆數為零，我會記錄訊息並返回。 否則，我將使用 `INSERT INTO ZEN_B2B_JSON_SO SELECT * FROM ZEN_B2B_JSON_TMP` 的語句，並確保此操作在交易中執行，以保持資料庫的一致性。 為了確保程式碼的效率和穩定性，我將對此過程進行進一步的測試。


**Finalizing the Procedure**

我已在檢查 `ZEN_B2B_JSON_TMP` 的資料筆數後，確保若筆數為零，便記錄訊息並返回。若資料筆數大於零，則執行插入至 `ZEN_B2B_JSON_SO` 的 SQL 指令。我加入日誌訊息，並確保插入操作在交易中執行，以維持資料庫一致性。


**Refining the Approach**

我正在進一步細化解決方案。 我將在檢查 `ZEN_B2B_JSON_TMP` 的資料筆數後，若筆數為零，便記錄日誌並返回。 否則，我將使用 `INSERT INTO ZEN_B2B_JSON_SO SELECT * FROM ZEN_B2B_JSON_TMP` 語句，並確保此操作在交易中執行，以保持資料庫的一致性。



**Refining the Implementation**

我正在修改 `GenericExtractService.java` 檔案，以實現使用者要求的功能。我已成功加入檢查 `ZEN_B2B_JSON_TMP` 表格資料筆數的邏輯，並且在筆數為零時，記錄訊息並返回。在筆數大於零時，我將使用 `INSERT INTO ZEN_B2B_JSON_SO SELECT * FROM ZEN_B2B_JSON_TMP` 的 SQL 語句。我將確保此操作在交易中執行，以維持資料庫一致性。


**Refining the Approach**

我重新評估我的方法。 既然我已經確定了在 `ZEN_B2B_JSON_SO_TMP` 表格中沒有資料時，應該跳過插入 `ZEN_B2B_JSON_SO` 表格，那麼我將實作這個邏輯。 如果有資料，我就會執行插入操作。 程式碼整合測試以及效率的優化都將是下一步的重點。 我也將使用 transaction 來維護資料的一致性。


**Refining the Implementation**

我已經完成了主要的邏輯整合。我新增了對 `ZEN_B2B_JSON_TMP` 表格資料筆數的檢查，並在筆數不為零時，執行插入 `ZEN_B2B_JSON_SO` 的 SQL 語句。另外，為了確保資料庫的一致性，我已在事務中執行此操作。 我正在檢查與測試流程。

**Enhancing the Procedure**

我進一步整合了邏輯。 於 `extract()` 方法中，我已實作檢查 `ZEN_B2B_JSON_TMP` 表格是否有資料的步驟。 若資料筆數為零，我將記錄訊息並返回 0。 若筆數大於零，我會執行 SQL 語句插入至 `ZEN_B2B_JSON_SO`。 此插入動作會於事務中執行，以維持資料庫的一致性。 我將會進行測試以確保此過程的正確性。


**Enhancing the Procedure**

我現已加入檢查 `ZEN_B2B_JSON_TMP` 的資料筆數的邏輯，並且在資料筆數為零時，會記錄訊息並返回。在筆數大於零時，我會執行 `INSERT INTO ZEN_B2B_JSON_SO SELECT * FROM ZEN_B2B_JSON_TMP` 語句，並確保此操作在交易中執行以維持資料庫一致性。 我將會進行測試以確保此過程的正確性。


**Finalizing the Implementation**

我已在 `extract()` 方法中成功加入邏輯，檢查暫存表 `ZEN_B2B_JSON_SO_TMP` 的資料筆數。若筆數為零，我會記錄日誌並返回0，終止執行。 若資料筆數大於零，則會將資料從暫存表 `ZEN_B2B_JSON_SO_TMP` 插入至正式表 `ZEN_B2B_JSON_SO`。 此插入操作在交易中執行，以維持資料庫一致性。


**Integrating the Check**

我已經將資料筆數檢查邏輯整合到 `extract()` 方法中。 程式會先檢查 `ZEN_B2B_JSON_TMP` 是否有資料。 若筆數為零，則記錄訊息並返回。 若筆數大於零，則執行插入到 `ZEN_B2B_JSON_SO` 的 SQL 語句。我已確保插入操作在事務中進行。


**Enhancing the Procedure**

我進一步整合了邏輯。 於 `extract()` 方法中，我已實作檢查 `ZEN_B2B_JSON_TMP` 表格是否有資料的步驟。 若資料筆數為零，我將記錄訊息並返回 0。 若筆數大於零，我會執行 SQL 語句插入至 `ZEN_B2B_JSON_SO`。 此插入動作會於事務中執行，以維持資料庫的一致性。 我將會進行測試以確保此過程的正確性。


**Finalizing the Check**

我已經完成了在 `extract()` 方法中添加檢查 `ZEN_B2B_JSON_TMP` 資料筆數的邏輯。當筆數為零時，會記錄訊息並返回。當筆數大於零時，則將資料從 `ZEN_B2B_JSON_TMP` 寫入至 `ZEN_B2B_JSON_SO` 表格，並確保此操作在事務中執行。 我已加入對 `INSERT` 語句的欄位明確定義。

**Refining the Implementation**

我重新檢查程式碼，並在 `extract()` 方法中，完成了對 `ZEN_B2B_JSON_SO_TMP` 暫存表中資料筆數的檢查。 若資料筆數為零，我會記錄訊息並返回。 若資料筆數大於零，則會把資料從暫存表 `ZEN_B2B_JSON_SO_TMP` 寫入至正式表 `ZEN_B2B_JSON_SO`。 此插入動作會於交易中執行，以維持資料庫一致性。


**Integrating the Check**

我已經實作了在 `extract()` 方法中檢查 `ZEN_B2B_JSON_TMP` 暫存表中資料筆數的邏輯。若筆數為零，程式將記錄訊息並返回。若筆數大於零，程式則執行插入資料到 `ZEN_B2B_JSON_SO` 表格的 SQL 指令。我加入交易以確保資料庫一致性。


**Finalizing the Check**

我已在 `extract()` 方法中成功加入邏輯，檢查暫存表 `ZEN_B2B_JSON_SO_TMP` 的資料筆數。若筆數為零，程式將記錄訊息並返回。若筆數大於零，程式則執行插入 `ZEN_B2B_JSON_SO` 表格的 SQL 語句。我加入交易以確保資料庫的一致性，且已確認 SQL 語句中，有明確的欄位定義。


**Adjusting the Implementation**

我已在 `extract()` 方法中添加了新的邏輯。 現在，當 `ZEN_B2B_JSON_SO_TMP` 填入資料後，會檢查其資料筆數。如果沒有資料，則記錄訊息並返回。如果有資料，則將資料插入 `ZEN_B2B_JSON_SO` 中，並確保該操作在交易中進行。 我已確保 `ZEN_B2B_JSON_SO` 的欄位明確地被加入到 SQL 語句中，以避免任何問題。


**整合資料檢查邏輯**

我已在 `extract()` 方法中整合了新的邏輯。 現在，在執行現有的 SQL 腳本以填入暫存表 `ZEN_B2B_JSON_SO_TMP` 後，我將檢查資料筆數。 若資料筆數為零，我會記錄一條訊息並返回，終止執行。 若筆數大於零，我會執行一個 SQL 指令，將暫存表中的資料插入到正式表 `ZEN_B2B_JSON_SO` 中。 我已確保此插入操作在事務中執行，以維持資料庫的一致性。


</details></think>

---

好的，我了解您的需求。

將在 `GenericExtractService` 中加入邏輯：在將資料從各個 `extract.sql` 檔案寫入 `ZEN_B2B_JSON_SO_TMP` 暫存表後，會先檢查暫存表中的資料筆數。

1.  如果暫存表 `ZEN_B2B_JSON_SO_TMP` 中沒有資料 (筆數為 0)，程式將會記錄一則訊息並中止後續的執行。
2.  如果暫存表中有資料 (筆數 > 0)，則會將所有資料從 `ZEN_B2B_JSON_SO_TMP` 新增至正式表 `ZEN_B2B_JSON_SO`。

這將確保只有在確實抽取出資料時，才會更新正式表。

以下是 `src/main/java/com/znt/outbound/service/GenericExtractService.java` 的更新內容：

```java:src/main/java/com/znt/outbound/service/GenericExtractService.java
// ... existing code ...
        int inserted = cnt != null ? cnt : 0;
        log.info("[{}] 抽取單據完成，寫入 ZEN_B2B_JSON_SO_TMP 共 {} 筆",
                LocalDateTime.now(), inserted);

        if (inserted == 0) {
            log.info("暫存表 ZEN_B2B_JSON_SO_TMP 中沒有資料，終止執行。");
            return 0;
        }

        // 步驟 3: 將暫存表資料寫入正式表
        log.info("開始將資料從 ZEN_B2B_JSON_SO_TMP 寫入 ZEN_B2B_JSON_SO。");
        transactionTemplate.execute(status -> {
            try {
                String insertSql = """
                    INSERT INTO ZEN_B2B_JSON_SO (
                        SEQ_ID, SENDER_CODE, RECEIVER_CODE, STATUS, DIRECTION, DOC_DATETIME,
                        LAST_UPDATE_DATE, CREATION_DATE, USER_NO, ID, ORDER_NO, INV_SPLIT,
                        INVOICE_NO, INVOICE_DATE, EXP_SHIP_DATE, CUST_NO, DEPT, CUST_NAME,
                        INVOICE_ADDRESS, SHIP_TO_NO, DELIVERY_ADDRESS, SHIP_TO_CONTACT,
                        SHIP_TO_PHONE, ZT_PART_NO, CUST_PART_NO, CUSTOMER_PO, SHIP_NOTICE,
                        SHIP_NOTES, STATUS1, BRAND, QUANTITY, UNIT_PRICE, AMOUNT, CUST_PO,
                        CUST_PO2, CUST_POLINE, CUST_PN, CUST_PN2, ITEM_DESC, ITEM_MODE,
                        ORDER_LINE_MEMO, UNIT_WEIGHT, WEIGHT_UOM_CODE, FROM_SUBINVENTORY_CODE,
                        SEGMENT1, SEGMENT2, KIND, SUPPLIER_PARTNO, INV_AND_PAC, CUST_PART_NO2,
                        PO_REMARK, RMA_NUMBER, ORD_TYPE, QC_TYPE
                    )
                    SELECT
                        SEQ_ID, SENDER_CODE, RECEIVER_CODE, STATUS, DIRECTION, DOC_DATETIME,
                        LAST_UPDATE_DATE, CREATION_DATE, USER_NO, ID, ORDER_NO, INV_SPLIT,
                        INVOICE_NO, INVOICE_DATE, EXP_SHIP_DATE, CUST_NO, DEPT, CUST_NAME,
                        INVOICE_ADDRESS, SHIP_TO_NO, DELIVERY_ADDRESS, SHIP_TO_CONTACT,
                        SHIP_TO_PHONE, ZT_PART_NO, CUST_PART_NO, CUSTOMER_PO, SHIP_NOTICE,
                        SHIP_NOTES, STATUS1, BRAND, QUANTITY, UNIT_PRICE, AMOUNT, CUST_PO,
                        CUST_PO2, CUST_POLINE, CUST_PN, CUST_PN2, ITEM_DESC, ITEM_MODE,
                        ORDER_LINE_MEMO, UNIT_WEIGHT, WEIGHT_UOM_CODE, FROM_SUBINVENTORY_CODE,
                        SEGMENT1, SEGMENT2, KIND, SUPPLIER_PARTNO, INV_AND_PAC, CUST_PART_NO2,
                        PO_REMARK, RMA_NUMBER, ORD_TYPE, QC_TYPE
                    FROM ZEN_B2B_JSON_SO_TMP
                    """;
                int insertedToMain = jdbcTemplate.update(insertSql);
                log.info("成功將 {} 筆資料從 ZEN_B2B_JSON_SO_TMP 寫入 ZEN_B2B_JSON_SO。", insertedToMain);
            } catch (DataAccessException e) {
                log.error("從 ZEN_B2B_JSON_SO_TMP 寫入 ZEN_B2B_JSON_SO 時發生錯誤", e);
                status.setRollbackOnly();
            }
            return null;
        });

        return inserted;
    }
}
```

我已經更新了 `extract` 方法，加入了您要求的邏輯。如果沒有其他問題，我就完成了。

---

_**User**_

你認為上述這段insert into ZEN_B2B_JSON_SO 應該要再獨立一隻程式寫還是照你原本的寫法寫在同一支程式裡?

---

_**Assistant**_

<think><details><summary>Thought Process</summary>**Assessing Code Architecture**

I'm currently weighing the pros and cons of modularizing the data insertion logic. Should I create a dedicated service or keep it within the existing one? It seems like extracting this logic would increase the complexity, but it would also enhance reusability and maintainability.


**Refining Data Insertion Logic**

I've been examining the current approach of keeping the data insertion logic within the `GenericExtractService`. The immediate simplicity is appealing, with the entire extract-check-insert workflow contained. This method also guarantees atomicity from the runner's perspective, streamlining the process. State management is also straightforward because I can readily access the inserted count within the same method. Finally, I noticed the transaction, wrapped around the final insert into `ZEN_B2B_JSON_SO`, provides transactional integrity.


**Considering Service Decoupling**

I've been analyzing the implications of separating the loading logic into a dedicated service. While keeping it within `GenericExtractService` simplifies the current flow, I'm now grappling with the trade-offs. The potential benefits are becoming clearer.  The separation enhances reusability, simplifies state management in the current use case, and improves the overall maintainability for any potential future use cases. 


**Deciding Code Organization**

I'm now contemplating the potential architectural benefits and complexities. While keeping the loading logic within `GenericExtractService` simplifies the immediate workflow, separating the concerns becomes increasingly appealing. Creating a new `GenericLoadService` offers enhanced reusability, testability, and flexibility for future development. The primary trade-off is the slight increase in complexity, which may necessitate more state management between the extraction and loading services.


**Recommending Code Structure**

I've been analyzing the design choices, considering both approaches. While keeping the loading within `GenericExtractService` offers immediate simplicity, I'm now leaning toward separating it into a `GenericLoadService`.  Although it introduces a slight complexity increase, the benefits in terms of reusability, testability, and adherence to the Single Responsibility Principle are becoming more compelling for the long term. This approach promotes a more robust and scalable architecture, aligning with best practices.


**Finalizing Code Recommendations**

I'm now determining the most appropriate code structure. Keeping the loading logic within the `GenericExtractService` simplifies the immediate workflow. However, separating it into a `GenericLoadService` is emerging as the better long-term solution. While it introduces a slight complexity increase, the benefits in reusability, testability, and adherence to the Single Responsibility Principle are very appealing. This approach promotes a more robust and scalable architecture, aligning with recommended practices. I'll outline the `GenericLoadService` and the adapted runner to complete the decision.

I believe this proposed architecture would provide superior code maintainability and scalability down the line. I'll sketch a `GenericLoadService` that focuses solely on the final insertion. The `GenericExtractService` would then extract to the temporary table, while `GenericLoadService` handles moving data to its final destination. This separation provides improved testability and flexibility for future needs. The `DbExtractRunner` would then coordinate calls to each service. This gives a clearer approach from the current implementation.


**Revising Service Decomposition**

I've been analyzing the best approach for data transfer, and have determined that separating `GenericLoadService` would be advantageous. I propose a modularized architecture where `GenericExtractService` focuses solely on data extraction to a temporary table, while `GenericLoadService` handles the final insertion. This split improves modularity and scalability, aligning with best practices.  The transactional boundaries will still be handled in `LoadService` and the transaction template.


**Evaluating Service Separation**

I've been working on structuring the data transfer process. I'm now evaluating whether to decompose the extraction and loading operations into separate services, namely `GenericExtractService` and a new `GenericLoadService`. The goal is to improve maintainability and flexibility while balancing the current simplicity. I'll need to refactor the `DbExtractRunner` to coordinate between the extract and load services. This approach offers enhanced reusability and aligns better with common ETL patterns.

**Analyzing Decomposition Benefits**

I've been evaluating the design choices, and I propose a modularized architecture with `GenericExtractService` for data extraction to a temporary table and `GenericLoadService` for the final insertion into `ZEN_B2B_JSON_SO`. This split aligns better with ETL principles, enhancing maintainability, testability, and flexibility. The transactional boundaries will still be within `LoadService` and the transaction template. The coordination of the services will be implemented in the runner.


**Assessing Service Decoupling**

I've been analyzing the best approach for data transfer, and I propose a modularized architecture where `GenericExtractService` focuses on data extraction to a temporary table and `GenericLoadService` handles the final insertion. This split aligns better with ETL principles, enhancing maintainability, testability, and flexibility. The transactional boundaries will still be within `LoadService`.


**Decomposing for Maintainability**

I'm now considering the benefits of separating the data loading process. The proposed modular architecture, featuring `GenericExtractService` for data extraction to a temporary table and `GenericLoadService` for final insertion, offers improved maintainability, testability, and adherence to ETL principles. This structure facilitates flexibility. The transactional boundaries will still be within the `LoadService`, and the runner service will coordinate extraction and loading.


**Assessing Code Structure**

I'm recommending separating the data loading process into a dedicated service. While the initial approach offered simplicity, the benefits in maintainability, reusability, and scalability offered by a `GenericLoadService` are compelling. This change aligns better with ETL principles and will improve the overall long-term architecture. The runner will coordinate the extract and load operations.

**Refining Code Recommendations**

I'm recommending separating the data loading process into a dedicated service. While the initial approach offered simplicity, the benefits in maintainability, reusability, and scalability offered by a `GenericLoadService` are compelling. This change aligns better with ETL principles and will improve the overall long-term architecture. The runner will coordinate the extract and load operations.


</details></think>

---

這是一個很好的設計問題。兩種做法都有其優缺點，選擇哪一種取決於您對這個專案的長期規劃和設計哲學。

讓我為您分析一下這兩種方法的利弊：

### 方法一：維持現狀，寫在同一支 `GenericExtractService` 中 (您目前採用的寫法)

這支 Service 的職責是「抽取資料並載入到正式表」。

*   **優點:**
    *   **流程簡單直觀**: 整個「抽取到暫存 -> 檢查 -> 寫入正式表」的邏輯被封裝在一個方法呼叫中 (`extract()`)，對於目前的需求來說，非常易於理解和追蹤。
    *   **狀態管理容易**: `inserted` 的筆數在同一個方法內，可以直接使用，不需要額外的傳遞或查詢。

*   **缺點:**
    *   **違反單一職責原則 (Single Responsibility Principle, SRP)**: `GenericExtractService` 實際上做了兩件事：1. 從來源抽取資料到暫存表 (Extract)。 2. 從暫存表載入資料到正式表 (Load)。這使得這個類別的職責不夠單一。
    *   **重用性較低**: 如果未來有其他程式也需要執行「從暫存表載入到正式表」這個操作，這段邏輯嵌在 `extract` 方法中，無法輕易地被重用。

### 方法二：獨立成一支新的 `LoadService`

將 `INSERT INTO ZEN_B2B_JSON_SO` 的邏輯移到一個新的 Service，例如 `LoadService`。

*   **優點:**
    *   **符合單一職責原則**: `GenericExtractService` 只負責「抽取」，`LoadService` 只負責「載入」。每個類別的職責都非常清晰，有利於長期維護。
    *   **高重用性与可擴展性**: `LoadService` 可以被任何需要它的地方注入和使用。如果未來流程變複雜，例如需要在 Extract 和 Load 之間增加一個 Transform (資料轉換) 的步驟，可以輕易地再建立一個 `TransformService`，並在主流程中像積木一樣組合起來 (`extract -> transform -> load`)。這是典型的 ETL (Extract-Transform-Load) 設計模式，擴展性非常好。
    *   **易於測試**: 可以針對 `Extract` 和 `Load` 的功能分別撰寫更簡單、更聚焦的單元測試。

*   **缺點:**
    *   **輕微增加複雜度**: 需要多建立一個類別 (`LoadService`)，並且執行器 (`DbExtractRunner`) 需要注入兩個 Service 並協調它們的呼叫。

### 我的建議

**我會建議採用第二種方法，也就是將載入邏輯獨立到一支新的 `LoadService` 中。**

雖然對於目前的需求來說，第一種方法比較快也夠用，但從軟體工程的長遠角度來看，第二種方法提供了更清晰的架構、更好的擴展性和可維護性。這種設計上的分離將讓您的程式碼庫在未來需求變更或功能擴增時更有彈性。

如果您同意這個方向，我可以為您進行以下修改：
1.  建立一個新的 `LoadService.java` 檔案，並將從 `TMP` 表寫入 `SO` 表的邏輯移入。
2.  修改 `GenericExtractService.java`，讓它的 `extract` 方法只負責抽取資料到 `TMP` 表並回傳筆數。
3.  更新 `DbExtractRunner.java` 來協調 `extractService` 和 `loadService` 的運作。

請告訴我您的決定。

---

_**User**_

請以方法二進行修改

---

_**Assistant**_

<think><details><summary>Thought Process</summary>**Analyzing Refactor Strategy**

I'm currently focused on refactoring the code. My latest thoughts revolve around implementing "Method 2" as I initially suggested. This necessitates a new `LoadService.java` to handle data loading from `ZEN_B2B_JSON_SO_TMP` to `ZEN_B`. The next step is clearly to design and write the `LoadService`, keeping in mind the architecture requirements.


**Developing Load Service Logic**

I'm now fully immersed in developing the `LoadService.java`. The plan is for it to handle the data transfer from `ZEN_B2B_JSON_SO_TMP` to `ZEN_B2B_JSON_SO`, as initially proposed. I'm focusing on crafting the `load()` method to ensure efficient and reliable data loading, paying close attention to error handling and transactional integrity. I aim to leverage `JdbcTemplate` for database interactions and `TransactionTemplate` for managing transactions. Next steps involve fine-tuning the SQL queries for optimal performance.


**Defining Data Flow Changes**

I'm now clarifying the scope of my changes. I'll need to create `LoadService.java` to manage data loading from the temporary table `ZEN_B2B_JSON_SO_TMP` to the main table `ZEN_B2B_JSON_SO`. The `extract` method within `GenericExtractService.java` will then exclusively focus on populating the temporary table and returning the insertion count. Finally, the `DbExtractRunner.java` needs to call both the extraction and the new loading service as appropriate.


**Defining LoadService Functionality**

I've been working on defining the `loadFromTmpToMain()` method within the `LoadService.java`. My current focus is on constructing the INSERT statement that efficiently transfers data from `ZEN_B2B_JSON_SO_TMP` to `ZEN_B2B_JSON_SO`, considering all required columns. I'm also planning to utilize the `TransactionTemplate` to ensure data integrity during the load operation, handling any potential exceptions effectively. The next step is to test this method with sample data to validate its functionality.


**Defining Insert Logic**

Now I'm focusing on defining the insert logic for the new `LoadService.java`. The `loadFromTmpToMain` method will move data from `ZEN_B2B_JSON_SO_TMP` to `ZEN_B2B_JSON_SO`. I've constructed an INSERT statement to efficiently transfer all the required columns. I'm leveraging `TransactionTemplate` for transactional control and proper error handling. The plan is to test this new service with sample data to ensure it correctly handles data transfer and integrity.


**Integrating the New Service**

I'm now integrating the `LoadService` into `DbExtractRunner.java`. My plan involves injecting `LoadService` into the runner and calling it after `GenericExtractService` completes. I'll check the number of extracted records, and then, if the extraction was successful, invoke the load method of the `LoadService`. I've made sure to handle potential exceptions that may arise during this process. The next step will be to test the complete flow and ensure it functions as intended.


**Refining Data Loading**

I'm revisiting the `LoadService` to address potential database connection issues. I'll utilize a `try-catch` block within the `transactionTemplate.execute()` method to ensure robust exception handling. This will involve logging detailed error information and optionally rethrowing a custom exception for better error propagation if needed. I'll test the changes by simulating data loading failures to ensure that the error handling is functioning correctly.


**Orchestrating the New Flow**

I'm now integrating the `LoadService` into the `DbExtractRunner.java`. I've added a call to the new service if the extract step from `GenericExtractService` returns data. The `DbExtractRunner` will check if records were extracted to the temporary table, and if so, it'll trigger the load operation. I've updated the logging accordingly to reflect the complete extraction and loading cycle.


**Optimizing Data Transfer**

I'm currently working on refactoring the data flow. I've designed and implemented the `LoadService.java` to handle the transfer from the temporary table to the main table, as initially planned. The `GenericExtractService` has been streamlined to solely focus on populating the temporary table. Finally, I've updated the `DbExtractRunner.java` to orchestrate both the extraction and loading processes, ensuring data integrity with transaction management.


</details></think>

---

好的，我們採用方法二來重構程式碼。

這將會分為三個步驟：
1.  建立一個新的 `LoadService`，專門負責將資料從暫存表 (`TMP`) 載入到正式表 (`SO`)。
2.  修改 `GenericExtractService`，使其只專注於從來源系統抽取資料到暫存表。
3.  更新 `DbExtractRunner`，讓它來協調 `Extract` 和 `Load` 的流程。

這樣做可以讓程式碼架構更清晰、職責更分明。

---

### 1. 建立 `LoadService.java`

我將建立一個新的 `LoadService` 檔案來處理資料載入的邏輯。

```java:src/main/java/com/znt/outbound/service/LoadService.java
package com.znt.outbound.service;

import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.dao.DataAccessException;
import org.springframework.jdbc.core.JdbcTemplate;
import org.springframework.stereotype.Service;
import org.springframework.transaction.support.TransactionTemplate;

@Service
@RequiredArgsConstructor
@Slf4j
public class LoadService {

    private final JdbcTemplate jdbcTemplate;
    private final TransactionTemplate transactionTemplate;

    public void loadFromTmpToMain() {
        log.info("開始將資料從 ZEN_B2B_JSON_SO_TMP 寫入 ZEN_B2B_JSON_SO。");
        transactionTemplate.execute(status -> {
            try {
                String insertSql = """
                    INSERT INTO ZEN_B2B_JSON_SO (
                        SEQ_ID, SENDER_CODE, RECEIVER_CODE, STATUS, DIRECTION, DOC_DATETIME,
                        LAST_UPDATE_DATE, CREATION_DATE, USER_NO, ID, ORDER_NO, INV_SPLIT,
                        INVOICE_NO, INVOICE_DATE, EXP_SHIP_DATE, CUST_NO, DEPT, CUST_NAME,
                        INVOICE_ADDRESS, SHIP_TO_NO, DELIVERY_ADDRESS, SHIP_TO_CONTACT,
                        SHIP_TO_PHONE, ZT_PART_NO, CUST_PART_NO, CUSTOMER_PO, SHIP_NOTICE,
                        SHIP_NOTES, STATUS1, BRAND, QUANTITY, UNIT_PRICE, AMOUNT, CUST_PO,
                        CUST_PO2, CUST_POLINE, CUST_PN, CUST_PN2, ITEM_DESC, ITEM_MODE,
                        ORDER_LINE_MEMO, UNIT_WEIGHT, WEIGHT_UOM_CODE, FROM_SUBINVENTORY_CODE,
                        SEGMENT1, SEGMENT2, KIND, SUPPLIER_PARTNO, INV_AND_PAC, CUST_PART_NO2,
                        PO_REMARK, RMA_NUMBER, ORD_TYPE, QC_TYPE
                    )
                    SELECT
                        SEQ_ID, SENDER_CODE, RECEIVER_CODE, STATUS, DIRECTION, DOC_DATETIME,
                        LAST_UPDATE_DATE, CREATION_DATE, USER_NO, ID, ORDER_NO, INV_SPLIT,
                        INVOICE_NO, INVOICE_DATE, EXP_SHIP_DATE, CUST_NO, DEPT, CUST_NAME,
                        INVOICE_ADDRESS, SHIP_TO_NO, DELIVERY_ADDRESS, SHIP_TO_CONTACT,
                        SHIP_TO_PHONE, ZT_PART_NO, CUST_PART_NO, CUSTOMER_PO, SHIP_NOTICE,
                        SHIP_NOTES, STATUS1, BRAND, QUANTITY, UNIT_PRICE, AMOUNT, CUST_PO,
                        CUST_PO2, CUST_POLINE, CUST_PN, CUST_PN2, ITEM_DESC, ITEM_MODE,
                        ORDER_LINE_MEMO, UNIT_WEIGHT, WEIGHT_UOM_CODE, FROM_SUBINVENTORY_CODE,
                        SEGMENT1, SEGMENT2, KIND, SUPPLIER_PARTNO, INV_AND_PAC, CUST_PART_NO2,
                        PO_REMARK, RMA_NUMBER, ORD_TYPE, QC_TYPE
                    FROM ZEN_B2B_JSON_SO_TMP
                    """;
                int insertedToMain = jdbcTemplate.update(insertSql);
                log.info("成功將 {} 筆資料從 ZEN_B2B_JSON_SO_TMP 寫入 ZEN_B2B_JSON_SO。", insertedToMain);
            } catch (DataAccessException e) {
                log.error("從 ZEN_B2B_JSON_SO_TMP 寫入 ZEN_B2B_JSON_SO 時發生錯誤", e);
                status.setRollbackOnly();
            }
            return null;
        });
    }
}
```

### 2. 修改 `GenericExtractService.java`

現在，`GenericExtractService` 只需要專注於抽取資料，並回傳抽取的筆數。

```java:src/main/java/com/znt/outbound/service/GenericExtractService.java
// ... existing code ...
        int inserted = cnt != null ? cnt : 0;
        log.info("[{}] 抽取單據完成，寫入 ZEN_B2B_JSON_SO_TMP 共 {} 筆",
                LocalDateTime.now(), inserted);

        return inserted;
    }
}
```

### 3. 更新 `DbExtractRunner.java`

最後，更新 `DbExtractRunner` 來協調整個流程。它會先呼叫 `extractService`，如果確定有資料，再呼叫 `loadService`。

```java:src/main/java/com/znt/outbound/runner/DbExtractRunner.java
package com.znt.outbound.runner;

import com.znt.outbound.service.GenericExtractService;
import com.znt.outbound.service.LoadService;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.boot.CommandLineRunner;
import org.springframework.stereotype.Component;

@Component      
@RequiredArgsConstructor
@Slf4j
public class DbExtractRunner implements CommandLineRunner {

    private final GenericExtractService extractService;
    private final LoadService loadService;

    @Override
    public void run(String... args) {
        log.info(">>> 開始執行資料庫抽取與載入任務...");
        int extractedCount = extractService.extract();

        if (extractedCount > 0) {
            log.info(">>> 已抽取 {} 筆資料至暫存表，準備載入正式表...", extractedCount);
            loadService.loadFromTmpToMain();
            log.info(">>> 資料載入任務完成。");
        } else {
            log.info(">>> 暫存表中無新資料，任務結束。");
        }
    }
}
```

這樣就完成了重構。程式現在的結構更加清晰，且易於未來的擴充與維護。如果沒有其他問題，我就完成了。

---

